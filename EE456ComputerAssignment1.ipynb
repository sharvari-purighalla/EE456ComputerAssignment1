{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time\n",
    "from typing import Dict, Any, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== constants =====\n",
    "UCI_URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "REQUIRED_COLS = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"]\n",
    "NUM_COLS = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== logging / utils =====\n",
    "def log(msg: str, initials: str, student_id: str) -> None:\n",
    "    \"\"\"Print a timestamped message tagged with student initials and 9-digit ID.\"\"\"\n",
    "    print(f\"[{time.strftime('%H:%M:%S')}] [{SPP}-{907394064}] {msg}\")\n",
    "\n",
    "def ensure_dir(path: str) -> None:\n",
    "    \"\"\"Create directory if it does not exist.\"\"\"\n",
    "    os.makedirs(path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "          - Read CSV from self.url with header=None and names=REQUIRED_COLS.\n",
    "          - Drop empty rows.\n",
    "          - Set self.df and return it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== data loader (implementations required) =====\n",
    "class IrisLoaderUCI:\n",
    "    def __init__(self, url: str = UCI_URL):\n",
    "        self.url = url\n",
    "        self.df: Optional[pd.DataFrame] = None\n",
    "\n",
    "    def load(self) -> pd.DataFrame:\n",
    "        df = pd.read_csv(\n",
    "            UCI_URL,\n",
    "            header = None,\n",
    "            names = REQUIRED_COLS\n",
    "        )\n",
    "\n",
    "        df.dropna().reset_index(drop=True)\n",
    "        self.df = df\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "          - Compute per-class counts for 'species'.\n",
    "          - total = number of rows.\n",
    "          - proportions = counts / total, rounded to 6 decimals.\n",
    "          - Return dict: {\"total\": int, \"counts\": {class: int}, \"proportions\": {class: float}}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    " def check_class_balance(self) -> Dict[str, Any]:\n",
    "        counts = self.df[\"species\"].value_counts().to_dict()\n",
    "        props = self.df[\"species\"].value_counts(normalize=True).round(6).to_dict()\n",
    "        out = {\"counts\": counts, \"proportions\": props}\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "          - Use the last two digits of `student_id` as the random seed. (e.g student_id = 202312345 -> seed = 45)\n",
    "          - Deterministically shuffle the DataFrame (use the provided seed).\n",
    "          - Take the first k rows and save to out_csv without index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_head(self, k: int = 10, out_csv: str = \"./outputs/head.csv\", seed: int = None) -> None:\n",
    "\n",
    "    # seed is last two digigts of PSU ID\n",
    "    seed = int(str(student_id)[-2:])\n",
    "    tmp = self.df.sample(frac=1, random_state=seed).head(k)\n",
    "    tmp.to_csv(out, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "          - Call check_class_balance() and save the resulting dict as JSON to out_json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_class_balance(self, out_json: str = \"./outputs/class_balance.json\") -> None:\n",
    "        rep = self.check_class_balance()\n",
    "        with open(out, \"w\") as f:\n",
    "            json.dump(rep, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== processor (implementations required) =====\n",
    "class Processor:\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.copy()\n",
    "\n",
    "    def add_numeric_label(self, out_map: str = \"./outputs/label_map.json\") -> None:\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "          - From self.df[\"species\"], build alphabetical class list and mapping to integers {0..K-1}.\n",
    "          - Create self.df[\"label\"] via the mapping.\n",
    "          - Save the mapping dict to JSON at out_map.\n",
    "        \"\"\"\n",
    "        species_sorted = sorted(self.df[\"species\"].unique())\n",
    "        label_map = {name: i for i, name in enumerate(species_sorted)}\n",
    "        self.df[\"label\"] = self.df[\"species\"].map(label_map).astype(int)\n",
    "\n",
    "        # save label map where main() tells you to\n",
    "        \n",
    "        self.label_map = label_map\n",
    "        return label_map\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "          - For each col in NUM_COLS, compute:\n",
    "              * min\n",
    "              * max\n",
    "              * mean\n",
    "              * median\n",
    "              * std\n",
    "          - Return dict in the form:\n",
    "              {\n",
    "                  \"sepal_length\": {\"min\":..., \"max\":..., \"mean\":..., \"median\":..., \"std\":...},\n",
    "                  \"sepal_width\": {...},\n",
    "                  ...\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(self) -> Dict[str, Any]:\n",
    "\n",
    "    stats_out: Dict[str, Dict[str, float]] = {}\n",
    "    for col in NUM_COLS:\n",
    "        s = self.df[col].astype(float)\n",
    "        stats_out[col] = {\n",
    "            \"min\": float(s.min()),\n",
    "            \"max\": float(s.max()),\n",
    "            \"mean\": float(s.mean()),\n",
    "            \"median\": float(s.median()),\n",
    "            \"std\": float(s.std(ddof=1)),\n",
    "        }\n",
    "    return stats_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TODO:\n",
    "          - Split the DataFrame **in order** (no shuffle).\n",
    "          - Validation size = round(n * val_ratio), clamp so both sets are >= 1 row.\n",
    "          - First part = val set, remaining = train set.\n",
    "          - Save to ./outputs/train.csv and ./outputs/val.csv (no index).\n",
    "          - Return {\"train_size\": int, \"val_size\": int}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(self, val_ratio: float = 0.2) -> Dict[str, Any]:\n",
    "    n = len(self.df)\n",
    "    v = int(round(n * val_ratio))\n",
    "    v = max(1, min(v, n - 1)) # clamp so 1..n-1\n",
    "    val_df = self.df.iloc[:v].copy()\n",
    "    train_df = self.df.iloc[v:].copy()\n",
    "   \n",
    "    self.train_df, self.val_df = train_df, val_df\n",
    "\n",
    "    return {\"train_size\": len(train_df), \"val_size\": len(val_df)}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def plot_hist(self, col: str = \"petal_length\", out: str = \"./outputs/hist_petal_length.png\") -> None:\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "          - Make a histogram with 20 bins for column `col`.\n",
    "          - Add title/xlabel/ylabel, tight_layout, save to `out` at dpi=150, then close the figure.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Implement Processor.plot_hist\")\n",
    "\n",
    "    def plot_label_bar(self, out: str = \"./outputs/label_bar.png\") -> None:\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "          - Create a bar chart of species counts (include NaN if any; sort by class name).\n",
    "          - Add title/xlabel/ylabel, tight_layout, save to `out` at dpi=150, then close the figure.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Implement Processor.plot_label_bar\")\n",
    "\n",
    "    def plot_scatter(self, x: str = \"petal_length\", y: str = \"petal_width\",\n",
    "                     color_by: str = \"species\", out: str = \"./outputs/scatter_petal.png\") -> None:\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "          - For each group in self.df grouped by `color_by` (include NaN group if any),\n",
    "            plot a scatter of x vs y with a legend.\n",
    "          - Add title/xlabel/ylabel, tight_layout, save to `out` at dpi=150, then close the figure.\n",
    "        Preconditions:\n",
    "          - Columns x, y, color_by exist in self.df.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Implement Processor.plot_scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def save_processed(self, out_csv: str = \"./outputs/processed.csv\") -> None:\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "          - Save the full processed DataFrame to out_csv without index.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Implement Processor.save_processed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== main driver (edit initials/ID; you may tweak seed/val_ratio) =====\n",
    "def main(initials: str, student_id: str, seed: int = 0, val_ratio: float = 0.2, uci_url: str = UCI_URL):\n",
    "    # Validate ID format (exactly 9 digits)\n",
    "    if not (isinstance(student_id, str) and student_id.isdigit() and len(student_id) == 9):\n",
    "        raise ValueError(\"student_id must be a string of exactly 9 digits, e.g., '202312345'.\")\n",
    "\n",
    "    ensure_dir(\"./outputs\")  # must be called exactly once\n",
    "    log(f\"Reading UCI CSV: {uci_url}\", initials, student_id)\n",
    "\n",
    "    loader = IrisLoaderUCI(url=uci_url)\n",
    "    df = loader.load()\n",
    "    log(f\"Loaded shape: {df.shape}\", initials, student_id)\n",
    "\n",
    "    balance = loader.check_class_balance()\n",
    "    loader.save_class_balance(\"./outputs/class_balance.json\")\n",
    "    log(f\"Class balance saved: counts={balance.get('counts')}, proportions={balance.get('proportions')}\",\n",
    "        initials, student_id)\n",
    "\n",
    "    loader.save_head(10, \"./outputs/head.csv\", seed=1)\n",
    "    log(\"Saved head.csv\", initials, student_id)\n",
    "\n",
    "    proc = Processor(df)\n",
    "    proc.add_numeric_label(\"./outputs/label_map.json\")\n",
    "    log(\"Added numeric label & saved label_map.json\", initials, student_id)\n",
    "\n",
    "    split_info = proc.train_val_split(val_ratio=val_ratio, seed=seed)\n",
    "    log(f\"Split: {split_info}\", initials, student_id)\n",
    "\n",
    "    stats = proc.stats()\n",
    "    with open(\"./outputs/stats.json\", \"w\") as f:\n",
    "        json.dump(stats, f, indent=2)\n",
    "    log(\"Saved stats.json\", initials, student_id)\n",
    "\n",
    "    proc.plot_hist(\"petal_length\", \"./outputs/hist_petal_length.png\")\n",
    "    proc.plot_label_bar(\"./outputs/label_bar.png\")\n",
    "    proc.plot_scatter(\"petal_length\", \"petal_width\", out=\"./outputs/scatter_petal.png\")\n",
    "    log(\"Saved plots\", initials, student_id)\n",
    "\n",
    "    proc.save_processed(\"./outputs/processed.csv\")\n",
    "    log(\"Saved processed.csv\", initials, student_id)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(initials=\"SPP\", student_id=\"907394064\")\n",
    "    self.train_df.to_csv(\"./outputs/train.csv\", index=False)\n",
    "    self.val_df.to_csv(\"./outputs/val.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (ee456)",
   "language": "python",
   "name": "ee456"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
