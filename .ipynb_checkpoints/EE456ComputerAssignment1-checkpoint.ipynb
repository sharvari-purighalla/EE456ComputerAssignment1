{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time\n",
    "from typing import Dict, Any, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== constants =====\n",
    "UCI_URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "REQUIRED_COLS = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"]\n",
    "NUM_COLS = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== logging / utils =====\n",
    "def log(msg: str, initials: str, student_id: str) -> None:\n",
    "    \"\"\"Print a timestamped message tagged with student initials and 9-digit ID.\"\"\"\n",
    "    print(f\"[{time.strftime('%H:%M:%S')}] [{initials}--{student_id}] {msg}\")\n",
    "\n",
    "def ensure_dir(path: str) -> None:\n",
    "    \"\"\"Create directory if it does not exist.\"\"\"\n",
    "    os.makedirs(path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "          - Read CSV from self.url with header=None and names=REQUIRED_COLS.\n",
    "          - Drop empty rows.\n",
    "          - Set self.df and return it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== data loader (implementations required) =====\n",
    "class IrisLoaderUCI:\n",
    "    def __init__(self, url: str = UCI_URL):\n",
    "        self.url = url\n",
    "        self.df: Optional[pd.DataFrame] = None\n",
    "\n",
    "    def load(self) -> pd.DataFrame:\n",
    "        df = pd.read_csv(\n",
    "            UCI_URL,\n",
    "            header = None,\n",
    "            names = REQUIRED_COLS\n",
    "        )\n",
    "\n",
    "        df.dropna().reset_index(drop=True)\n",
    "        self.df = df\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "          - Compute per-class counts for 'species'.\n",
    "          - total = number of rows.\n",
    "          - proportions = counts / total, rounded to 6 decimals.\n",
    "          - Return dict: {\"total\": int, \"counts\": {class: int}, \"proportions\": {class: float}}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " def check_class_balance(self) -> Dict[str, Any]:\n",
    "        counts = self.df[\"species\"].value_counts().to_dict()\n",
    "        props = self.df[\"species\"].value_counts(normalize=True).round(6).to_dict()\n",
    "        out = {\"counts\": counts, \"proportions\": props}\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "          - Use the last two digits of `student_id` as the random seed. (e.g student_id = 202312345 -> seed = 45)\n",
    "          - Deterministically shuffle the DataFrame (use the provided seed).\n",
    "          - Take the first k rows and save to out_csv without index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_head(self, k: int = 10, out_csv: str = \"./outputs/head.csv\", seed: int = None) -> None:\n",
    "\n",
    "    # seed is last two digigts of PSU ID\n",
    "    seed = int(str(student_id)[-2:])\n",
    "    tmp = self.df.sample(frac=1, random_state=seed).head(k)\n",
    "    tmp.to_csv(out, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "          - Call check_class_balance() and save the resulting dict as JSON to out_json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_class_balance(self, out_json: str = \"./outputs/class_balance.json\") -> None:\n",
    "        rep = self.check_class_balance()\n",
    "        with open(out, \"w\") as f:\n",
    "            json.dump(rep, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== processor (implementations required) =====\n",
    "class Processor:\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.copy()\n",
    "\n",
    "    def add_numeric_label(self, out_map: str = \"./outputs/label_map.json\") -> None:\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "          - From self.df[\"species\"], build alphabetical class list and mapping to integers {0..K-1}.\n",
    "          - Create self.df[\"label\"] via the mapping.\n",
    "          - Save the mapping dict to JSON at out_map.\n",
    "        \"\"\"\n",
    "        species_sorted = sorted(self.df[\"species\"].unique())\n",
    "        label_map = {name: i for i, name in enumerate(species_sorted)}\n",
    "        self.df[\"label\"] = self.df[\"species\"].map(label_map).astype(int)\n",
    "\n",
    "        # save label map where main() tells you to\n",
    "        \n",
    "        self.label_map = label_map\n",
    "        return label_map\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "          - For each col in NUM_COLS, compute:\n",
    "              * min\n",
    "              * max\n",
    "              * mean\n",
    "              * median\n",
    "              * std\n",
    "          - Return dict in the form:\n",
    "              {\n",
    "                  \"sepal_length\": {\"min\":..., \"max\":..., \"mean\":..., \"median\":..., \"std\":...},\n",
    "                  \"sepal_width\": {...},\n",
    "                  ...\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(self) -> Dict[str, Any]:\n",
    "\n",
    "    stats_out: Dict[str, Dict[str, float]] = {}\n",
    "    for col in NUM_COLS:\n",
    "        s = self.df[col].astype(float)\n",
    "        stats_out[col] = {\n",
    "            \"min\": float(s.min()),\n",
    "            \"max\": float(s.max()),\n",
    "            \"mean\": float(s.mean()),\n",
    "            \"median\": float(s.median()),\n",
    "            \"std\": float(s.std(ddof=1)),\n",
    "        }\n",
    "    return stats_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "          - Split the DataFrame **in order** (no shuffle).\n",
    "          - Validation size = round(n * val_ratio), clamp so both sets are >= 1 row.\n",
    "          - First part = val set, remaining = train set.\n",
    "          - Save to ./outputs/train.csv and ./outputs/val.csv (no index).\n",
    "          - Return {\"train_size\": int, \"val_size\": int}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(self, val_ratio: float = 0.2) -> Dict[str, Any]:\n",
    "    n = len(self.df)\n",
    "    v = int(round(n * val_ratio))\n",
    "    v = max(1, min(v, n - 1)) # clamp so 1..n-1\n",
    "    val_df = self.df.iloc[:v].copy()\n",
    "    train_df = self.df.iloc[v:].copy()\n",
    "   \n",
    "    self.train_df, self.val_df = train_df, val_df\n",
    "\n",
    "    return {\"train_size\": len(train_df), \"val_size\": len(val_df)}\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "        - Make a histogram with 20 bins for column `col`.\n",
    "        - Add title/xlabel/ylabel, tight_layout, save to `out` at dpi=150, then close the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(self, col: str = \"petal_length\", out: str = \"./outputs/hist_petal_length.png\") -> None:\n",
    "    plt.figure()\n",
    "    self.df[feature].astype(float).plot(kind=\"hist\", bins=20)\n",
    "    plt.xlabel(feature.replace(\"_\",\" \"))\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.title(f\"Histogram of {feature.replace('_',' ')}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out, dpi=150)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "          - Create a bar chart of species counts (include NaN if any; sort by class name).\n",
    "          - Add title/xlabel/ylabel, tight_layout, save to `out` at dpi=150, then close the figure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_label_bar(self, out: str = \"./outputs/label_bar.png\") -> None:\n",
    "    counts = self.df[\"species\"].value_counts()\n",
    "    plt.figure()\n",
    "    counts.plot(kind=\"bar\")\n",
    "    plt.xlabel(\"species\")\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.title(\"Species distribution\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out, dpi=150)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "          - For each group in self.df grouped by `color_by` (include NaN group if any),\n",
    "            plot a scatter of x vs y with a legend.\n",
    "          - Add title/xlabel/ylabel, tight_layout, save to `out` at dpi=150, then close the figure.\n",
    "        Preconditions:\n",
    "          - Columns x, y, color_by exist in self.df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(self, x: str = \"petal_length\", y: str = \"petal_width\",\n",
    "                     color_by: str = \"species\", out: str = \"./outputs/scatter_petal.png\") -> None:\n",
    "    plt.figure()\n",
    "    for name, grp in self.df.groupby(\"species\"):\n",
    "        plt.scatter(grp[x].astype(float), grp[y].astype(float), label=name, s=18)\n",
    "    plt.xlabel(x.replace(\"_\",\" \"))\n",
    "    plt.ylabel(y.replace(\"_\",\" \"))\n",
    "    plt.title(f\"{x.replace('_',' ')} vs {y.replace('_',' ')}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out, dpi=150)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "        - Save the full processed DataFrame to out_csv without index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    " def save_processed(self, out_csv: str = \"./outputs/processed.csv\") -> None:\n",
    "     if self.df is None: raise ValueError(\"No DataFrame\")\n",
    "     self.df.to_csv(out, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:12:13] [SPP--907394064] Reading UCI CSV: https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\n",
      "[19:12:13] [SPP--907394064] Loaded shape: (150, 5)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'IrisLoaderUCI' object has no attribute 'check_class_balance'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     40\u001b[39m     log(\u001b[33m\"\u001b[39m\u001b[33mSaved processed.csv\u001b[39m\u001b[33m\"\u001b[39m, initials, student_id)\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitials\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSPP\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudent_id\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m907394064\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m     \u001b[38;5;28mself\u001b[39m.train_df.to_csv(\u001b[33m\"\u001b[39m\u001b[33m./outputs/train.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     46\u001b[39m     \u001b[38;5;28mself\u001b[39m.val_df.to_csv(\u001b[33m\"\u001b[39m\u001b[33m./outputs/val.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(initials, student_id, seed, val_ratio, uci_url)\u001b[39m\n\u001b[32m     11\u001b[39m df = loader.load()\n\u001b[32m     12\u001b[39m log(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, initials, student_id)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m balance = \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheck_class_balance\u001b[49m()\n\u001b[32m     15\u001b[39m loader.save_class_balance(\u001b[33m\"\u001b[39m\u001b[33m./outputs/class_balance.json\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m log(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mClass balance saved: counts=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbalance.get(\u001b[33m'\u001b[39m\u001b[33mcounts\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, proportions=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbalance.get(\u001b[33m'\u001b[39m\u001b[33mproportions\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m     initials, student_id)\n",
      "\u001b[31mAttributeError\u001b[39m: 'IrisLoaderUCI' object has no attribute 'check_class_balance'"
     ]
    }
   ],
   "source": [
    "# ===== main driver (edit initials/ID; you may tweak seed/val_ratio) =====\n",
    "def main(initials: str, student_id: str, seed: int = 0, val_ratio: float = 0.2, uci_url: str = UCI_URL):\n",
    "    # Validate ID format (exactly 9 digits)\n",
    "    if not (isinstance(student_id, str) and student_id.isdigit() and len(student_id) == 9):\n",
    "        raise ValueError(\"student_id must be a string of exactly 9 digits, e.g., '202312345'.\")\n",
    "\n",
    "    ensure_dir(\"./outputs\")  # must be called exactly once\n",
    "    log(f\"Reading UCI CSV: {uci_url}\", initials, student_id)\n",
    "\n",
    "    loader = IrisLoaderUCI(url=uci_url)\n",
    "    df = loader.load()\n",
    "    log(f\"Loaded shape: {df.shape}\", initials, student_id)\n",
    "\n",
    "    balance = loader.check_class_balance()\n",
    "    loader.save_class_balance(\"./outputs/class_balance.json\")\n",
    "    log(f\"Class balance saved: counts={balance.get('counts')}, proportions={balance.get('proportions')}\",\n",
    "        initials, student_id)\n",
    "\n",
    "    loader.save_head(10, \"./outputs/head.csv\", seed=1)\n",
    "    log(\"Saved head.csv\", initials, student_id)\n",
    "\n",
    "    proc = Processor(df)\n",
    "    proc.add_numeric_label(\"./outputs/label_map.json\")\n",
    "    log(\"Added numeric label & saved label_map.json\", initials, student_id)\n",
    "\n",
    "    split_info = proc.train_val_split(val_ratio=val_ratio, seed=seed)\n",
    "    log(f\"Split: {split_info}\", initials, student_id)\n",
    "\n",
    "    stats = proc.stats()\n",
    "    with open(\"./outputs/stats.json\", \"w\") as f:\n",
    "        json.dump(stats, f, indent=2)\n",
    "    log(\"Saved stats.json\", initials, student_id)\n",
    "\n",
    "    proc.plot_hist(\"petal_length\", \"./outputs/hist_petal_length.png\")\n",
    "    proc.plot_label_bar(\"./outputs/label_bar.png\")\n",
    "    proc.plot_scatter(\"petal_length\", \"petal_width\", out=\"./outputs/scatter_petal.png\")\n",
    "    log(\"Saved plots\", initials, student_id)\n",
    "\n",
    "    proc.save_processed(\"./outputs/processed.csv\")\n",
    "    log(\"Saved processed.csv\", initials, student_id)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(initials=\"SPP\", student_id=\"907394064\")\n",
    "    self.train_df.to_csv(\"./outputs/train.csv\", index=False)\n",
    "    self.val_df.to_csv(\"./outputs/val.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (ee456)",
   "language": "python",
   "name": "ee456"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
